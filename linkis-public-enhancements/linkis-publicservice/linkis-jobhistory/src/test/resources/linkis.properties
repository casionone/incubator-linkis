# 
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#
##enable wds.linkis.test.mode where use knife4j
#wds.linkis.test.mode=true
wds.linkis.server.version=v1
##spring conf
wds.linkis.gateway.url=http://127.0.0.1:9001
wds.linkis.eureka.defaultZone=http://127.0.0.1:20303/eureka/
##mybatisINIT=CREATE SCHEMA IF NOT EXISTS linkis_test
#wds.linkis.server.mybatis.datasource.url=jdbc:h2:mem:linkis_test;INIT=RUNSCRIPT FROM 'classpath:create.sql'"
wds.linkis.server.mybatis.datasource.url=jdbc:h2:mem:test;MODE=MySQL;DB_CLOSE_DELAY=-1;DATABASE_TO_LOWER=true;INIT=runscript from 'classpath:create.sql'

wds.linkis.server.mybatis.datasource.username=sa
wds.linkis.server.mybatis.datasource.password=
wds.linkis.server.mybatis.datasource.driver-class-name=org.h2.Driver

#hadoopconfig
#hadoop.config.dir=/appcom/config/hadoop-config
#hive.config.dir=
#spark.config.dir
##file path
wds.linkis.filesystem.root.path=file:///tmp/linkis/
wds.linkis.filesystem.hdfs.root.path=hdfs:///tmp/linkis/
##bml path:default use hdfs
wds.linkis.bml.is.hdfs=true
wds.linkis.bml.hdfs.prefix=/apps-data
#wds.linkis.bml.local.prefix=/data/dss/bml
##engine Version
#wds.linkis.spark.engine.version=
#wds.linkis.hive.engine.version=
#wds.linkis.python.engine.version=
#LinkisHome
wds.linkis.home=/appcom/Install/LinkisInstall
#Linkis governance station administrators
wds.linkis.governance.station.admin=hadoop
wds.linkis.gateway.conf.publicservice.list=query,jobhistory,application,configuration,filesystem,udf,variable,microservice,errorcode,bml,datasource

spring.spring.servlet.multipart.max-file-size=500MB
spring.spring.servlet.multipart.max-request-size=500MB

# note:value of zero means Jetty will never write to disk. https://github.com/spring-projects/spring-boot/issues/9073
spring.spring.servlet.multipart.file-size-threshold=50MB

#test
wds.linkis.test.mode=true
wds.linkis.test.user=hadoop

spring.spring.h2.console.enabled=true
spring.spring.datasource.url=jdbc:h2:mem:test
#Disable discovery
spring.spring.cloud.discovery.enabled=false

#Disable cloud config and config discovery
spring.spring.cloud.config.discovery.enabled=false
spring.spring.cloud.config.enabled=false

spring.spring.cloud.service-registry.auto-registration.enabled=false
eureka.client.enabled=false
eureka.client.serviceUrl.registerWithEureka=false